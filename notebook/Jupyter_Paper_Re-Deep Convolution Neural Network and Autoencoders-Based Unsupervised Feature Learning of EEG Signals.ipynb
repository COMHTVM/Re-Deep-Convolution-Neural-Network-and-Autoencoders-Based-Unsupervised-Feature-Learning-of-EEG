{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/gist/bruAristimunha/351cf17d387f03078981f8b45e720872/jupyter_paper_re-deep-convolution-neural-network-and-autoencoders-based-unsupervised-feature-learning-of-eeg-signals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. [Re] [Deep Convolution Neural Network and Autoencoders-Based Unsupervised Feature Learning of EEG Signals](https://doi.org/10.1109/ACCESS.2018.2833746)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Reproduction authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have no affiliation with the original authors, and in the attempts to contact there was no return.\n",
    "\n",
    "\n",
    "[Bruno Aristimunha](https://github.com/bruAristimunha)*<sup>1</sup>, [Diogo Eduardo Lima Alves](https://github.com/DiogoEduardo)*<sup>1</sup>, [Walter Hugo Lopez Pinaya](https://github.com/warvito) <sup>1,2</sup>, [Raphael Y. de Camargo](https://rycamargo.wixsite.com) <sup>1</sup>\n",
    "\n",
    "> <sup>1</sup> Center for Mathematics, Computation and Cognition (CMCC), Federal Univesity of ABC (UFABC), Rua Arcturus, 03. Jardim Antares, São Bernardo do Campo, CEP 09606-070, SP, Brazil.\n",
    "\n",
    "> <sup>2</sup> Department of Psychosis Studies, Institute of Psychiatry, Psychology & Neuroscience, King’s College London, London, UK.\n",
    "\n",
    ">*b.aristimunha@gmail.com, digmogle96@gmail.com\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Original authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tingxi Wen <sup>2</sup>, Zhongnan Zhang* <sup>2</sup>\n",
    "\n",
    "> <sup>2</sup> Software School, Xiamen University, Xiamen, China.\n",
    "\n",
    "*zhongnan_zhang@xmu.edu.cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Abstract (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper describes our efforts to implement, acquire similar results and improvement of the ones achieved by the authors of the original article. We follow the steps and models described in their article and the same public data sets of EEG Signals. Epilepsy affects more than 65 million people globally, and EEG Signals are critical to analyze and recognize epilepsy. Although the efforts in the last years, it is still challenging to extract useful information from these signals and select useful features from numerous them in a diagnostic application. We construct a deep convolution network and autoencoders-based model (AE-CDNN) in order to perform unsupervised feature learning. We use the AE-CDNN to extract the features of the available data sets, and then we use some common classifiers to classify the features. The results obtained demonstrate that the proposed AE-CDNN to perform the traditional feature extraction based classification techniques by achieving better accuracy of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keywords: Reproduction, Epilepsy, Auto-Enconder, EEG.\n",
    "\n",
    "---\n",
    "\n",
    "Responsible for the reproduction of the results: [Bruno Aristimunha](https://github.com/bruAristimunha) and [Diogo Eduardo Lima Alves](https://github.com/DiogoEduardo).\n",
    "\n",
    "The goals in the work is:\n",
    "    - Make a reproducible report of the results previously reported;\n",
    "    - Improve and deepen the analyzes already carried out in the original article;\n",
    "\n",
    "\n",
    "Advisors: [Walter Hugo Lopez Pinaya](https://github.com/warvito) and [Raphael Y. de Camargo](https://rycamargo.wixsite.com/home) \n",
    "\n",
    "***\n",
    "\n",
    "This work follows the structure below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-[Re]-Deep-Convolution-Neural-Network-and-Autoencoders-Based-Unsupervised-Feature-Learning-of-EEG-Signals\" data-toc-modified-id=\"1.-[Re]-Deep-Convolution-Neural-Network-and-Autoencoders-Based-Unsupervised-Feature-Learning-of-EEG-Signals-1\">1. [Re] <a href=\"https://doi.org/10.1109/ACCESS.2018.2833746\" target=\"_blank\">Deep Convolution Neural Network and Autoencoders-Based Unsupervised Feature Learning of EEG Signals</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-Reproduction-authors.\" data-toc-modified-id=\"1.1-Reproduction-authors.-1.1\">1.1 Reproduction authors.</a></span></li><li><span><a href=\"#1.2-Original-authors.\" data-toc-modified-id=\"1.2-Original-authors.-1.2\">1.2 Original authors.</a></span></li></ul></li><li><span><a href=\"#2.-Abstract-(text)\" data-toc-modified-id=\"2.-Abstract-(text)-2\">2. Abstract (text)</a></span></li><li><span><a href=\"#3.-Imports-Packages-(code)\" data-toc-modified-id=\"3.-Imports-Packages-(code)-3\">3. Imports Packages (code)</a></span></li><li><span><a href=\"#4.-Introduction-(text):\" data-toc-modified-id=\"4.-Introduction-(text):-4\">4. Introduction (text):</a></span></li><li><span><a href=\"#5.-Related-Work-(text)-\" data-toc-modified-id=\"5.-Related-Work-(text)--5\">5. Related Work (text) <a name=\"related\"></a></a></span></li><li><span><a href=\"#6.-Methodology-Proposal-(text-and-code)-\" data-toc-modified-id=\"6.-Methodology-Proposal-(text-and-code)--6\">6. Methodology Proposal (text and code) <a name=\"propose\"></a></a></span><ul class=\"toc-item\"><li><span><a href=\"#6.1-Implementation-Details-(text)\" data-toc-modified-id=\"6.1-Implementation-Details-(text)-6.1\">6.1 Implementation Details (text)</a></span></li><li><span><a href=\"#6.2-Autoencoders\" data-toc-modified-id=\"6.2-Autoencoders-6.2\">6.2 Autoencoders</a></span></li><li><span><a href=\"#6.3-Feature-Learning-Model\" data-toc-modified-id=\"6.3-Feature-Learning-Model-6.3\">6.3 Feature Learning Model</a></span></li><li><span><a href=\"#6.4-Classification\" data-toc-modified-id=\"6.4-Classification-6.4\">6.4 Classification</a></span></li></ul></li><li><span><a href=\"#7.-Experimental-Methodology-\" data-toc-modified-id=\"7.-Experimental-Methodology--7\">7. Experimental Methodology <a name=\"metho\"></a></a></span><ul class=\"toc-item\"><li><span><a href=\"#7.1-Bonn-University-EEG-database\" data-toc-modified-id=\"7.1-Bonn-University-EEG-database-7.1\">7.1 Bonn University EEG database</a></span></li><li><span><a href=\"#7.2-Children's-Hospital-of-Boston-EEG-database\" data-toc-modified-id=\"7.2-Children's-Hospital-of-Boston-EEG-database-7.2\">7.2 Children's Hospital of Boston EEG database</a></span></li><li><span><a href=\"#7.3-Performance-Measures\" data-toc-modified-id=\"7.3-Performance-Measures-7.3\">7.3 Performance Measures</a></span></li><li><span><a href=\"#7.4-Data-Management-(code)\" data-toc-modified-id=\"7.4-Data-Management-(code)-7.4\">7.4 Data Management (code)</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.4.1-Download-Data-(code)\" data-toc-modified-id=\"7.4.1-Download-Data-(code)-7.4.1\">7.4.1 Download Data (code)</a></span></li><li><span><a href=\"#7.4.3-Checking-the-Variance-(code)\" data-toc-modified-id=\"7.4.3-Checking-the-Variance-(code)-7.4.2\">7.4.3 Checking the Variance (code)</a></span></li><li><span><a href=\"#7.4.5-Split-data-and-pre-processing-(code)\" data-toc-modified-id=\"7.4.5-Split-data-and-pre-processing-(code)-7.4.3\">7.4.5 Split data and pre-processing (code)</a></span></li></ul></li><li><span><a href=\"#7.5-Performing-feature-learning-(code)\" data-toc-modified-id=\"7.5-Performing-feature-learning-(code)-7.5\">7.5 Performing feature learning (code)</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.5.1-Building-and-saving-dimension-reduction-(code)\" data-toc-modified-id=\"7.5.1-Building-and-saving-dimension-reduction-(code)-7.5.1\">7.5.1 Building and saving dimension reduction (code)</a></span></li></ul></li><li><span><a href=\"#7.6-Classification-process-(code)\" data-toc-modified-id=\"7.6-Classification-process-(code)-7.6\">7.6 Classification process (code)</a></span></li></ul></li><li><span><a href=\"#8.-Results-and-Discussion-\" data-toc-modified-id=\"8.-Results-and-Discussion--8\">8. Results and Discussion <a name=\"resu\"></a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Network-Model-Feature-Extraction-Analysis\" data-toc-modified-id=\"Network-Model-Feature-Extraction-Analysis-8.1\">Network Model Feature Extraction Analysis</a></span></li><li><span><a href=\"#Comparison-of-Dimension-Reduction-Methods\" data-toc-modified-id=\"Comparison-of-Dimension-Reduction-Methods-8.2\">Comparison of Dimension Reduction Methods</a></span></li><li><span><a href=\"#Comparison-of-Classification-Application\" data-toc-modified-id=\"Comparison-of-Classification-Application-8.3\">Comparison of Classification Application</a></span></li></ul></li><li><span><a href=\"#9.-Conclusion-\" data-toc-modified-id=\"9.-Conclusion--9\">9. Conclusion <a name=\"concl\"></a></a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-10\">References</a></span></li><li><span><a href=\"#Appendixes\" data-toc-modified-id=\"Appendixes-11\">Appendixes</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Imports Packages (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports packages which are used by jupyter paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T20:56:39.072618Z",
     "start_time": "2020-03-27T20:56:38.003717Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "CONFIG = ConfigProto()\n",
    "CONFIG.gpu_options.allow_growth = True\n",
    "SESSION = InteractiveSession(config=CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T20:56:39.075739Z",
     "start_time": "2020-03-27T20:56:39.073800Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "sys.path.append(\"../code/chb-mit/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T20:56:39.766031Z",
     "start_time": "2020-03-27T20:56:39.076699Z"
    }
   },
   "outputs": [],
   "source": [
    "from data_management import (\n",
    "    download_bonn,\n",
    "    download_chbmit,\n",
    "    load_dataset_boon,\n",
    "    load_dataset_chbmit,\n",
    "    preprocessing_split,\n",
    ")\n",
    "\n",
    "from variance import (\n",
    "    get_variance_accumulated,\n",
    "    get_variance_by_file,\n",
    "    get_variance_by_pearson,)\n",
    "\n",
    "from dimension_reduction import (\n",
    "    reduce_dimension,\n",
    "    build_feature,\n",
    ")\n",
    "\n",
    "from classification import (\n",
    "    methods_classification,\n",
    "    save_classification,\n",
    "    run_classification, \n",
    "    run_classification_nn,\n",
    ")\n",
    "\n",
    "from visualization import (\n",
    "    plot_variance_accumulate,\n",
    "    plot_variance_by_file,\n",
    "    plot_variance_by_pearson,\n",
    "    plot_average_accuracy,\n",
    "    plot_feature_distribution,\n",
    "    plot_change_loss,\n",
    "    table_classification_dimension,\n",
    "    table_classification_fold,\n",
    "    plot_average_accuracy_baseline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T20:56:39.769204Z",
     "start_time": "2020-03-27T20:56:39.766975Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "EPOCHS = 5000\n",
    "BATCH = 256\n",
    "PATH_BOON = '../data/boon/'\n",
    "PATH_CHBMIT = '../data/chbmit/'\n",
    "chbmit_url = 'https://physionet.org/files/chbmit/1.0.0/'\n",
    "\n",
    "n_dims = [2, 4, 8, 16, 32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Introduction (text):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epilepsy is a chronic neurological disorder, and it is becoming one of the most common neurological diseases in the world. Approximately $1\\%$ of the world's population is affected by epilepsy representing more than 65 million people affected. This disorder is characterized by the occurrence of spontaneous convulsions due to the abnormal synchronous firing of the cortical neurons. This physical reaction can generate many problems for patients, including physical harm caused by the loss of consciousness, shame and discrimination.\n",
    "\n",
    "Frequent seizures are dangerous conditions because, at the moment of disruption of the body can occur falls, fractures, burns, car accidents, and other serious physical injuries. Epilepsy can be defined as a permanent predisposition in the brain to cause epileptic seizures.\n",
    "\n",
    "A person is diagnosed with epilepsy if they have two unprovoked seizures (or one unprovoked seizure with the likelihood of more) that were not caused by some known and reversible medical condition like alcohol withdrawal or extremely low blood sugar. Even when correctly diagnosed and treated, the epileptic patient still suffers side effects and sporadic seizures. The epileptic seizures can cause even irreversible damage to the brain, and then we can visualize the importance of analyzing epilepsy to improve the life quality and the medical treatments for these patients.\n",
    "\n",
    "To confirm the diagnostic, epileptologists should usually visually inspect the long-term electroencephalograms (EEG) of the scalp. EEG is a measure of the voltage fluctuation generated by the ion current of neurons in the brain, which reflects the activity of the brain’s bio-electricity and may contain many physiological and disease information. \n",
    "\n",
    "After the discovery that during a patient's seizure the brain activity changes, the EEG has become the most common epilepsy diagnostic tool. Many studies have been made, and the general problem consists in acquiring methods to classify the patients' EEG signals efficiently. \n",
    "\n",
    "However, this costly task still presents several challenges for automatic crisis detection, among them: The scarce number of public data sets; The lack of standardization in seizure classification methodologies; The lack of standardization of data preprocessing; The cost of a specialist to label time intervals; The unbalance of the time series given the rare occurrence of the event; The difficulty of reproducing the works in the literature.\n",
    "\n",
    "With this problem in hand, this paper reproduces the results obtained in <a id=\"ref-1\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>, with public data labeled and preprocessed. In addition, we get new results by combining the proposal classifiers into a classifier by set voting, and we add new metrics.\n",
    "\n",
    "The remainder of this paper is organized as follows: Section [5](#related) presents a few works related to the classification of epileptic seizures in EGG. Section [6](#propose) introduce the methodological proposal employed, and their differences with the work of <a id=\"ref-2\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>. Section [7](#metho) lists the experimental validation process using epilepsy datasets. Section [8](#resu) presents the corresponding results and analyzes our approach. Finally, conclusions were summarized in Section [9](#concl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Related Work (text) <a name=\"related\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several papers use automated methods for detecting seizures. We can extract several discriminative characteristics of the signals, among them, we mention the autocorrelation, probability of synchronization, functional connectivity network properties, EEG morphology and the reconstructed powers of the time series. \n",
    "\n",
    "The oscillatory characteristics present in the time series of patients with epilepsy were extensively studied by temporal frequency analysis for classification (<a id=\"ref-3\" href=\"#cite-saab2005system\">Saab and Gotman 2005</a>, <a id=\"ref-4\" href=\"#cite-kuhlmann2009seizure\">Kuhlmann et al. 2009</a>, <a id=\"ref-5\" href=\"#cite-shoeb2004patient\">Shoeb et al. 2004</a>, <a id=\"ref-6\" href=\"#cite-shoeb2011machine\">Shoeb et al. 2011</a>). Using this technique, we mention the Discrete Wavelet Transform (DWT), which, despite requiring hand-designed parameters, it is the most used (<a id=\"ref-7\" href=\"#cite-ullah2018automated\">Ullah et al. 2018</a>).\n",
    "\n",
    "In the literature, there is no standard rule for manually label seizures in databases, which makes it difficult to compare the results of these methods. Besides the few papers that use the same sets, few are looking for the same task.\n",
    "\n",
    "In <a id=\"ref-8\" href=\"#cite-chua2011application\">Chua et al. 2011</a>, it is used High Order Spectra (HOS) and spectrum-based energy resources for the automated detection of epilepsy. The proposed method yields good results when using Gaussian Mixture (GMM) for classification ($93.11\\%$ and $88.78\\%$). In <a id=\"ref-9\" href=\"#cite-nicolaou2012detection\">Nicolaou and Georgiou 2012</a>, we have that the authors extracted the entropy of the permutation of the signals, and employed these in an SVM for classification. The result of this methodology, acquired $93.55\\%$ for our first database, in task A vs E.\n",
    "\n",
    "Some researchers have applied Deep Belief Networks (DBNs) to the detection of seizures (<a id=\"ref-10\" href=\"#cite-acharya2018deep\">Acharya et al. 2018</a>). In the line of deep learning algorithms, Convolutional Neural Networks (CNNs) attract growing interest in the literature. In <a id=\"ref-11\" href=\"#cite-hussein2018epileptic\">Hussein et al. 2018</a>, they propose a CNN that learns based on the spectral information of each channel and a LSTM network with a single layer to classify the channels of the objects. \n",
    "\n",
    "<a id=\"ref-12\" href=\"#cite-xun2016detecting\">Xun et al. 2016</a> propose an approach unusual when decoding each window of possible interval as an ``EEG word`` from the `EEG` dictionary. They explore temporal knowledge by learning context information from EEG fragments (Context-EEG). The authors obtained a $22.93\\%$ error rate in the control classification vs epileptic crisis using the second dataset present in <a id=\"ref-13\" href=\"#cite-WenZha\">Wen and Zhang, 2018</a>. \n",
    "\n",
    "<a id=\"ref-14\" href=\"#cite-emami2019autoencoding\">Emami et al. 2019</a> obtained $100\\%$ sensitivity with a simpler methodology than our. For each channel, it builds a autoencoder and through the error of reconstruction is classified. The dataset was self and with no access available. <a id=\"ref-15\" href=\"#cite-ullah2018automated\">Ullah et al. 2018</a> propose a pyramidal model of one dimension for convolution (P-1D-CNN). The method obtains $99.1$ $\\pm$ $0.9$ in our first dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Methodology Proposal (text and code) <a name=\"propose\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we describe implementation details, since the core here is the reproducible aspect of our reference article. We introduce the idea and implementation of autoencoder/feature learning and our version of the model in <a id=\"ref-16\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>, explaining the differences we have made to the original model.\n",
    "\n",
    "In our study, we keep the autoencoder and feature learning as proposed. However, in the classification, we no longer consider classifiers individually; these methods now make up a large ensemble learning classifier, which decides by majority vote the object class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Implementation Details (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to reproduce the implementation described in the article using Keras (<a id=\"ref-17\" href=\"#cite-chollet2018keras\">Chollet et al. 2018</a>) and backend in TensorFlow (<a id=\"ref-18\" href=\"#cite-tensorflow\">Abadi et al. 2016</a>). Our repository includes the list of all the required libraries employed in acquiring the datasets and running the model (the original and the proposed one). According to the methodology proposed in <a id=\"ref-19\" href=\"#cite-Fuente:2019\">la Fuente and Aduviri 2019</a>, we store all the checkpoints for the trained models, for reproduction purposes. Besides that, the training logs can be visualized using TensorBoard tool.\n",
    "\n",
    "Given the lack of information about implementation in the original paper, some assumptions or cuts are made: \n",
    "\n",
    "* The number of epoch in the auto-enconder is assumed to be $5000$; \n",
    "* The number of samples per batch size is assumed to be $500$; \n",
    "* A column of the first database is removed, there is disagreement in the literature on the total instances, $4097$ or $4096$. In the specific database we use there is $4097$. The removed attribute is at the endpoint of each object; \n",
    "* The classifier presented in the final subsection was not reproduced for lack of information; \n",
    "* The loss function presented in equation $12$ of the <a id=\"ref-20\" href=\"#cite-WenZha\">Wen and Zhang, 2018</a> was implemented and we also compared the result obtained with MAPE; \n",
    "* The value of the seeds selected in all classifiers was $42$; \n",
    "* The train-test ratio was $80\\%-20\\%$; \n",
    "* The test data were used for validation in auto-enconder;\n",
    "* In the second dataset, considering the information gap, we use the channel reported by the author to train the AutoEncoder;\n",
    "\n",
    "\n",
    "The experiments were performed using a CPU with Intel Core i7-5930K with 3.50 GHz and two GPUs: Nvidia Quadro K5200 and GeForce GTX 970. Some experiments were also run using Nvidia Titan X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autoencoder implemented is a specific case of neural network structure. It is formed by three layers, the input layer, output layer and a hidden layer. The training is done to set the weights of hidden layer to force the input layer and output layer to be as close to each other as possible. Our features are extracted from the hidden layer, which reduces the dimension of data.\n",
    "\n",
    "Therefore we have a\tencoding process and a decoding process, and we obtain the hidden layer $h$ by applying the encoding function:\n",
    "\n",
    "\\begin{equation}\n",
    "h = encoder(x) = g(W*x+b),\n",
    "\\end{equation}\n",
    "\n",
    "where $W$ is the weight matrix between input layer and hidden layer. In the decoding function the hidden layer $h$ is the input and $y = decoder(h)$ as output, the function is defined as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "y = decoder(x) = g(W'*x + b'),\n",
    "\\end{equation}\n",
    "\n",
    "where $W'$ is the weight matrix between hidden layer and output layer. Since we want input and output to be as close as possible, we have the object function for the model training process:\n",
    "\n",
    "$$\\min \\sum |y^{(i)} - x^{(i)}|,$$\n",
    "\n",
    "where $y^{(i)}$ is the output signal and $x^{(i)}$ is the input signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Feature Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection, we will omit equations and minor details (for complete information, see <a id=\"ref-21\" href=\"#cite-Shoeb\">Shoeb and Guttag 2010</a>, <a id=\"ref-22\" href=\"#cite-emami2019autoencoding\">Emami et al. 2019</a>). Since we have the dimension reduced by autoencoder we focus on the next challenge: how to obtain effective features from EEG signals.  The AE-CDNN implemented follows the steps:\n",
    "\n",
    "\n",
    "    Encoder: sample input, convolution layer, down-sampling layer, reshape operation, full connection layer, and the feature coding.\n",
    "    \n",
    "    Decoder: feature coding as input, full connection layer, reshape operation, deconvolution layer, up-sampling layer and the reconstruction samples.\n",
    "\n",
    "Basically, the convolution layer acts as our feature extractor. It performs many successive convolution calculations of the input data and the expectation is to maintain the main components of the input data. The pooling layer is a down-sampling method which reduces data dimension. It uses windows to slide and extract the feature maps. These intervals do not overlap each other, and with then we obtain the pooled feature maps. The feature sizes tested were $m \\in \\{2, 4, 8, 16, 32, 64, 128, 256\\}$[<sup>1</sup>](#fn1 \"footnote 1\").\n",
    "\n",
    "\n",
    "\n",
    "The convolution and pooling operations can be iterated multiple times. Reshape operation uses the pooled feature maps to construct a one-dimension vector and a full-connection layer to transform this one-dimension vector. \n",
    "\n",
    "Considering $x$ as the input and $y$ as the output, now we need to re-transform the one-dimension vector which will generate the $y$ output, recall we want to minimize the difference between $x$ and $y$, we have the following equation to calculate loss:\n",
    "\n",
    "$$\\text{Loss }= \\frac{1}{N} \\sum_{i=1}^N |x^{(i)} - y^{(i)}| .$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<sup>1. <span id=\"fn1\"> Size $m = 256$ has not been tested in <a id=\"ref-23\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>.</span></sup> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have extracted the features with reduced dimension, we use supervised learning models on these features in order to classify the EEG signals. We evaluate each classifier and then we compare the results obtained with each one. The classical classifiers used are: K-Nearest Neighbors (K-NN), Support-Vector Machine - Linear Kernel and Radial Basis kernel (SVM1, SVM2), Decision Tree (DT), Random Forest (RT), Multilayer Neural Network (MLP), Adaptive Boosting algorithm (ADB) and  Gaussian Naive Bayesian (GNB).\n",
    " \n",
    "The proposed modification combines these classifiers and creates a single classifier that decides by voting. In short, the classifiers were combined by ensemble learning, and the result of the classification became the classification most voted by the classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Experimental Methodology <a name=\"metho\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this paper, as in our reference paper <a id=\"ref-24\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>, we use unsupervised learning method in EEG signals in order to obtain useful features. This process is needed because the original data is high-dimensional. By using the auto-encoder, we can extract features with reduced dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.1 Bonn University EEG database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use different approaches to detect epileptic crisis. Then, to acquire a comparative measure, we verify our outputs using the method described in [6](#propose) and the original one showed in <a id=\"ref-25\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>. This database is public and was published by <a id=\"ref-26\" href=\"#cite-Andrzejak\">G. Andrzejak et al. 2002</a>. The study groups were the control, inter-ictal and ictal distributed into five sets (denotated A-E). Each containing $100$ records of $23.6$ seconds duration and frequency of $173.6$ Hz on a single channel, with $12$-bit resolution. Each data segment has 4097 samples. These recordings underwent a pre-processing in which the signals had a band filter between $0.53$ to $40$ Hz. There was also the removal of artifacts such as muscle movements or flicker movements.\n",
    "\n",
    "Using labels A, B, C, D and E for the subsets, we have that A and B contain records of 5 healthy volunteers. Set A corresponds to open-eye activity and subset B to closed-eye activity. The subsets C and D have signals during the absence (interictal epileptiform activity) of 5 epileptic patients. And E records the signals during epileptic patients' seizure (ictal intervals). According to <a id=\"ref-27\" href=\"#cite-kamath2015analysis\">Kamath 2015</a>, this dataset is a compilation of recordings under different conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Children's Hospital of Boston EEG database\n",
    "\n",
    "The second database, also public, contains the EEG signals from a Children\\`s Hospital of Boston\n",
    "\\cite{Shoeb}. It was recorded by measuring the brain's electrical activity to obtain EEG signals by connecting multiple electrodes to the patients’ scalp. The data incorporates the EEG signals of 23 children with refractory epilepsy.\n",
    "\n",
    "This database, built in partnership with the Massachusetts Institute of Technology (MIT), has $5$ men and $18$ women between $3$ and $22$ years. The frequency range was $256$ Hz with $16$ resolution bits. Most patients contain $ 23 $ channels and some with $24$ channels. In contrast to the first set of data, we have multiple channels here, then we need to select channels. The selection followed the methodology used in \\cite{31}, which analyzes the variance of each patient, and after that, chooses the channel of greater variance to represent that individual. The channel reported by the authors was `FT9-FT10`.\n",
    "\n",
    "In the data of the first ten patients, 200 windows of the same size of the control set were chosen from the epileptic patients we choose $200$, with size of $4096$, in the same way of the control group.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Performance Measures\n",
    "\n",
    "According to <a id=\"ref-28\" href=\"#cite-roy2019deep\">Roy et al. 2019</a>, most of the state-of-the-art systems for epilepsy use the metrics defined below. The adaptation of these metrics for evaluating our system contributes to fair comparison with state-of-the-art systems. The definitions of these metrics are given in Table [1](#table1).\n",
    "\n",
    "\n",
    "| **Acurracy**      | **Precision** | **Specificity** | **Sensitivity** | **F-Measure**                                                |\n",
    "|:--------------------------:|:----------------------:|:------------------------:|:------------------------:|:---------------------------------------------------------------------:|\n",
    "| $\\frac{TP+TN}{(TP+TN+FP+FN)}$ | $\\frac{TP}{TP+FP}$      | $\\frac{TN}{TN+FP}$        | $\\frac{TP}{FN+TP}$        | $\\frac{2 * Pre * Sens}{Sens+Pre}$ |\n",
    "\n",
    "> Table 1. Metrics and Definition use in our paper. Only the Acurracy was considered in <a id=\"ref-29\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>. <a name=\"table1\"></a>\n",
    "\n",
    "\n",
    "where False Negatives - FN is the number of epileptic cases, which are predicted as control, True Positives - TP is the number of epileptic cases, which are predicted as epileptic, True Negative - TN is the number of control case that is predicted as control and False Positives - FP is the number of control cases that are identified as epileptic by the system. \n",
    "\n",
    "In addition, there was also the AUC-ROC (Area Under The Curve - Receiver Operating Characteristic) defined as the cumulative distribution function of the true positive rate vs the false-negative rate denoted by a threshold.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this for each subsection, we first perform the analysis of a dataset (__Bonn University__), and then repeat the same process for the second dataset (__Children's Hospital of Boston__)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.4 Data Management (code)\n",
    "\n",
    "In this section, we describe the operation required to reproduce the results. So, here is the code for downloading, sampling, and splitting the dataset.\n",
    "\n",
    "### 7.4.1 Download Data (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EEG data obtained from the experiment reported above  are required for reproduction. These files have $11$ Mb in Bonn University and $25$ Gb in Children's Hospital of Boston database. You do need them for all the analysis in the Jupyter Paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bonn University database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T20:56:39.856169Z",
     "start_time": "2020-03-27T20:56:39.769886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists\n",
      "Subfolders already exist\n"
     ]
    }
   ],
   "source": [
    "boon_path_child_fold = download_bonn(PATH_BOON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T20:56:40.118261Z",
     "start_time": "2020-03-27T20:56:39.859545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206M\t../data/boon/\r\n"
     ]
    }
   ],
   "source": [
    "! du -sh $PATH_BOON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Children's Hospital of Boston EEG database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T20:56:40.133987Z",
     "start_time": "2020-03-27T20:56:40.124080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the folder information: ../data/chbmit/\n",
      "Folder already exists\n",
      "Use load_dataset_chbmit\n"
     ]
    }
   ],
   "source": [
    "chbmit_path_child_fold = download_chbmit(url_base=chbmit_url,\n",
    "                                         path_save=PATH_CHBMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T20:56:40.318044Z",
     "start_time": "2020-03-27T20:56:40.138389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44G\t../data/chbmit/\r\n"
     ]
    }
   ],
   "source": [
    "! du -sh $PATH_CHBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "\n",
    "### 7.4.3 Checking the Variance (code) \n",
    "\n",
    "Given the possibilities of interpretation, we model the three scenarios for the interpretation of how the variance was calculated. \n",
    "\n",
    "To calculate the variance, we considered three scenarios for interpretation: in the first, we analyzed each recording file of the dataset as a sample; In the second scenario, we understand that each person is a sample, so the variance was calculated in parallel and combined for each person; Finally, we calculate the cumulative variance across all people and across all records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**1º Scenario:**\n",
    "\n",
    "For each file:\n",
    "* We calculated the variance of this file;\n",
    "* We order the values;\n",
    "* We take the channel with more variance;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T23:41:20.684415Z",
     "start_time": "2020-03-25T23:34:12.179891Z"
    }
   },
   "source": [
    "variance_by_file = get_variance_by_file(PATH_CHBMIT)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T23:41:21.022466Z",
     "start_time": "2020-03-25T23:41:20.685335Z"
    }
   },
   "source": [
    "fig_by_file = plot_variance_by_file(variance_by_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained in the first scenario were not consistent with those reported by the author."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**2º Scenario:**\n",
    "\n",
    "For each pearson:\n",
    "* For each file:\n",
    "    * We calculated the variance, size and the mean by channel;\n",
    "    * We calculate the accumulated variance with the previous information, using the parallel variance calculation algorithm.\n",
    "        \n",
    "* We take the channel with more variance by pearson;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T23:50:35.113632Z",
     "start_time": "2020-03-25T23:41:21.023421Z"
    }
   },
   "source": [
    "variance_per_person = get_variance_by_pearson(PATH_CHBMIT, range_= (1,11))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T23:50:35.237216Z",
     "start_time": "2020-03-25T23:50:35.114508Z"
    }
   },
   "source": [
    "fig_by_pearson = plot_variance_by_pearson(variance_per_person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained in the second scenario were not consistent with those reported by the author."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T22:30:01.404576Z",
     "start_time": "2020-03-20T22:30:01.398148Z"
    }
   },
   "source": [
    "---\n",
    "\n",
    "**3º Scenario:**\n",
    "\n",
    "* For each pearson:\n",
    "    * For each file:\n",
    "        * We calculated the variance, size and the mean by channel;\n",
    "        * We calculate the accumulated variance with the previous information, using the parallel variance calculation algorithm;\n",
    "    * We take the channel with more variance by pearson;\n",
    "* We propagate and accumulate the variance for all samples;\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T23:59:49.636574Z",
     "start_time": "2020-03-25T23:50:35.238127Z"
    }
   },
   "source": [
    "cout, avg, var = get_variance_accumulated(PATH_CHBMIT, range_= (1,11))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T23:59:49.806966Z",
     "start_time": "2020-03-25T23:59:49.638209Z"
    }
   },
   "source": [
    "fig_accumulate = plot_variance_accumulate(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained in the three scenario were not consistent with those reported by the author. Thus, not in any of the scenarios analyzed did we obtain the same results in the variance as the original authors.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "There is still another possible scenario, however, not reproducible, being the possibility that the authors randomly sampled the dataset and in this they verified the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T16:22:44.025132Z",
     "start_time": "2020-03-11T16:22:44.019409Z"
    }
   },
   "source": [
    "*Bonn University EEG database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T20:56:40.796369Z",
     "start_time": "2020-03-27T20:56:40.323269Z"
    }
   },
   "outputs": [],
   "source": [
    "X_boon, y_boon = load_dataset_boon(PATH_BOON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Children's Hospital of Boston EEG database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T20:56:41.789998Z",
     "start_time": "2020-03-27T20:56:40.797327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading as dataframe\n"
     ]
    }
   ],
   "source": [
    "X_chbmit, y_chbmit = load_dataset_chbmit(PATH_CHBMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "\n",
    "### 7.4.5 Split data and pre-processing (code)\n",
    "\n",
    "\n",
    "*Bonn University EEG database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T20:56:41.804045Z",
     "start_time": "2020-03-27T20:56:41.790956Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_boon, X_test_boon, Y_train_boon, Y_test_boon = preprocessing_split(X_boon, y_boon,\n",
    "                                                                           test_size=TEST_SIZE,\n",
    "                                                                           random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Children's Hospital of Boston EEG database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T20:56:41.880674Z",
     "start_time": "2020-03-27T20:56:41.804895Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_chbmit, X_test_chbmit, Y_train_chbmit, Y_test_chbmit = preprocessing_split(X_chbmit, y_chbmit,\n",
    "                                                                                   test_size=TEST_SIZE,\n",
    "                                                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Performing feature learning (code)\n",
    "\n",
    "In this section we present the dimension reduction process.\n",
    "\n",
    "### 7.5.1 Building and saving dimension reduction (code)\n",
    "\n",
    "In this sub-section has the dimension reduction process, in each dataset, either through methods baseline with Principal Component Analysis (`PCA`), Sparse Random Projection (`SRP`), or the proposal with Auto Encoder (`AE`).\n",
    "\n",
    "*Bonn University EEG database*\n",
    "\n",
    "__Auto Encoder (`AE`)__\n",
    "\n",
    "* Mean absolute error (`MAE`)\n",
    "* Mean absolute average error (`MAAE`)\n",
    "* Mean absolute percentage error (`MAPE`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:57:19.524958Z",
     "start_time": "2020-03-27T20:56:41.881991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert and save with value enconding dimension: mae - 2\n",
      "Convert and save with value enconding dimension: mae - 4\n",
      "Convert and save with value enconding dimension: mae - 8\n",
      "Convert and save with value enconding dimension: mae - 16\n",
      "Convert and save with value enconding dimension: mae - 32\n",
      "Convert and save with value enconding dimension: mae - 64\n",
      "Convert and save with value enconding dimension: mae - 128\n",
      "Convert and save with value enconding dimension: mae - 256\n",
      "Convert and save with value enconding dimension: maae - 2\n",
      "Convert and save with value enconding dimension: maae - 4\n",
      "Convert and save with value enconding dimension: maae - 8\n",
      "Convert and save with value enconding dimension: maae - 16\n",
      "Convert and save with value enconding dimension: maae - 32\n",
      "Convert and save with value enconding dimension: maae - 64\n",
      "Convert and save with value enconding dimension: maae - 128\n",
      "Convert and save with value enconding dimension: maae - 256\n",
      "Convert and save with value enconding dimension: mape - 2\n",
      "Convert and save with value enconding dimension: mape - 4\n",
      "Convert and save with value enconding dimension: mape - 8\n",
      "Convert and save with value enconding dimension: mape - 16\n",
      "Convert and save with value enconding dimension: mape - 32\n",
      "Convert and save with value enconding dimension: mape - 64\n",
      "Convert and save with value enconding dimension: mape - 128\n",
      "Convert and save with value enconding dimension: mape - 256\n"
     ]
    }
   ],
   "source": [
    "methods_ae_maae_boon = [[\n",
    "    build_feature(X_train_boon, X_test_boon,\n",
    "                  Y_train_boon, Y_test_boon,\n",
    "                  PATH_BOON, EPOCHS, BATCH, type_loss, dim)\n",
    "    for dim in n_dims]\n",
    "    for type_loss in [\"mae\", \"maae\", \"mape\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Principal Component Analysis (`PCA`)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:57:19.967436Z",
     "start_time": "2020-03-27T23:57:19.525853Z"
    }
   },
   "outputs": [],
   "source": [
    "methods_pca_boon = [\n",
    "    reduce_dimension(X_boon, y_boon,\n",
    "                     PATH_BOON, \"pca\", dim)\n",
    "    for dim in n_dims]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sparse Random Projection (`SRP`)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:57:20.104369Z",
     "start_time": "2020-03-27T23:57:19.968349Z"
    }
   },
   "outputs": [],
   "source": [
    "methods_srp_boon = [\n",
    "    reduce_dimension(X_boon, y_boon,\n",
    "                     PATH_BOON, \"srp\", dim)\n",
    "    for dim in n_dims]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Children's Hospital of Boston EEG database*\n",
    "\n",
    "__Auto Encoder (`AE`)__\n",
    "\n",
    "* Mean absolute error (`MAE`)\n",
    "* Mean absolute average error (`MAAE`)\n",
    "* Mean absolute percentage error (`MAPE`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert and save with value enconding dimension: mae - 2\n"
     ]
    }
   ],
   "source": [
    "methods_ae_mae_chbmit = [[\n",
    "    build_feature(X_train_chbmit, X_test_chbmit,\n",
    "                  Y_train_chbmit, Y_test_chbmit,\n",
    "                  PATH_CHBMIT, EPOCHS, BATCH, 'mae', dim)\n",
    "    for dim in n_dims]\n",
    "    for type_loss in [\"mae\", \"maae\", \"mape\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Principal Component Analysis (`PCA`)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.309Z"
    }
   },
   "outputs": [],
   "source": [
    "methods_pca_chbmit = [x \n",
    "    reduce_dimension(X_chbmit, y_chbmit,\n",
    "                     PATH_CHBMIT, \"pca\", dim)\n",
    "    for dim in n_dims]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sparse Random Projection (`SRP`)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.319Z"
    }
   },
   "outputs": [],
   "source": [
    "methods_srp_chbmit = [\n",
    "    reduce_dimension(X_chbmit, y_chbmit,\n",
    "                     PATH_CHBMIT, \"srp\", dim)\n",
    "    for dim in n_dims]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.6 Classification process (code)  \n",
    "\n",
    "*Bonn University EEG database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.326Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_boon = [run_classification(path_dataset=PATH_BOON,\n",
    "                                   name_type=name_type,\n",
    "                                   range_values=n_dims)\n",
    "                for name_type in [\"mae\", \"maae\", \"mape\", \"pca\", \"srp\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:44:21.838726Z",
     "start_time": "2020-03-11T15:44:21.826763Z"
    }
   },
   "source": [
    "*Children's Hospital of Boston EEG database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.334Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_chbmit = [run_classification(path_dataset=PATH_CHBMIT,\n",
    "                                     name_type=name_type,\n",
    "                                     range_values=n_dims)\n",
    "                  for name_type in [\"mae\", \"maae\", \"mape\", \"pca\", \"srp\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Results and Discussion <a name=\"resu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained in our reproduction experiment are presented in Table [2](#table:accuracy-ae-l1-d1),  [3](#table:accuracy-ae-l2-d1), [4](#table:accuracy-ae-l1-d2) and [5](#table:accuracy-ae-l2-d2). We employed the same methodology as the one used in the original paper, performing a 5-fold cross-validation of the accuracy for each classifier, and we show the mean values. We observe in the last column the values obtained by joining the classifiers by voting (**VotingClassifier**). In addition, we exploited an additional value of $ m $, i.e. the size of the latent feature vector of AE-CDNN-L1, which is $ m = 256 $. \n",
    "<!--\n",
    "The values observed in Tables [3](#table:Precision-Specificity-Sensitivity), [4](#table:F-Measure), [5](#table:auc-roc) demonstrate the results obtained for the proposed additional metrics that we consider important for understanding the behavior of the classifiers.\n",
    "-->\n",
    "\n",
    "## Network Model Feature Extraction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.345Z"
    }
   },
   "outputs": [],
   "source": [
    "table_classification_dimension(metrics_boon[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Table 2: Classification Accuracy Results of AE-CDNN-L1 for Dataset 1<a name=\"table:accuracy-ae-l1-d1\"></a>.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.355Z"
    }
   },
   "outputs": [],
   "source": [
    "table_classification_dimension(metrics_boon[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T00:12:10.326977Z",
     "start_time": "2020-03-22T00:12:10.321350Z"
    }
   },
   "source": [
    "> Table 3: Classification Accuracy Results of AE-CDNN-L2 for Dataset 1<a name=\"table:accuracy-ae-l2-d1\"></a>.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.363Z"
    }
   },
   "outputs": [],
   "source": [
    "table_classification_dimension(metrics_chbmit[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T00:12:34.628700Z",
     "start_time": "2020-03-22T00:12:34.622998Z"
    }
   },
   "source": [
    "> Table 4: Classification Accuracy Results of AE-CDNN-L1 for Dataset 2<a name=\"table:accuracy-ae-l1-d2\"></a>.\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.371Z"
    }
   },
   "outputs": [],
   "source": [
    "table_classification_dimension(metrics_chbmit[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Table 5: Classification Accuracy Results of AE-CDNN-L2 for Dataset 2<a name=\"table:accuracy-ae-l2-d2\"></a>.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos na Figura \\ref{} a média para o número de dimensões, com a diferentes funções de perda e conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.382Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_avg_acc = plot_average_accuracy(metrics_boon[0], metrics_boon[1],\n",
    "                                    metrics_chbmit[0], metrics_chbmit[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ m = 2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.394Z"
    }
   },
   "outputs": [],
   "source": [
    "table_classification_fold(metrics_boon[0], dimension=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.401Z"
    }
   },
   "outputs": [],
   "source": [
    "table_classification_fold(metrics_boon[1], dimension=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T01:54:34.161531Z",
     "start_time": "2020-03-22T01:54:34.148992Z"
    }
   },
   "source": [
    "Longo texto analisando as diferenças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.407Z"
    }
   },
   "outputs": [],
   "source": [
    "table_classification_fold(metrics_chbmit[0], dimension=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.413Z"
    }
   },
   "outputs": [],
   "source": [
    "table_classification_fold(metrics_chbmit[1], dimension=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "$m=4$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.421Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_feat_distri = plot_feature_distribution(PATH_BOON, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T04:00:42.563500Z",
     "start_time": "2020-03-22T04:00:42.554654Z"
    }
   },
   "source": [
    "Assumindo que ainda estamos falando do mesmo dataset, com mesmo número de tamanho de vetor."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-26T22:14:50.255676Z",
     "start_time": "2020-03-26T22:11:19.089Z"
    }
   },
   "source": [
    "history_l1 = methods_ae_mae_boon[1][0].method_autoenconder.history\n",
    "history_l2 = methods_ae_maae_boon[1][0].method_autoenconder.history\n",
    "\n",
    "fig_change_loss = plot_change_loss(history_l1, history_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Texto falando sobre o Baseline\n",
    "\n",
    "## Comparison of Dimension Reduction Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.458Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_avg_acc_base = plot_average_accuracy_baseline(metrics_boon[0], metrics_boon[1],\n",
    "                                                  metrics_boon[3], metrics_boon[4],\n",
    "                                                  metrics_chbmit[0], metrics_chbmit[1],\n",
    "                                                  metrics_chbmit[3], metrics_chbmit[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Classification Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não entendi como ele fez a comparação, é o auto-enconder e duas dimensões? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:43:58.910Z"
    }
   },
   "source": [
    "results_nn_16 = run_classification_nn(PATH_BOON, \"mae\", 16, cv=10, epochs=1000)\n",
    "#results_nn_32 = run_classification_nn(PATH_BOON, \"mae\", 32, cv=10, epochs=1000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:44:06.906Z"
    }
   },
   "source": [
    "results_nn_16[1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T20:37:24.751282Z",
     "start_time": "2020-03-27T20:37:24.746499Z"
    }
   },
   "source": [
    "import matplotlib.pylab as plt\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "historico = pd.DataFrame(results_nn_16[0]).T\n",
    "\n",
    "historico[0].plot.line(ax=ax)\n",
    "historico[1].plot.line(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Conclusion <a name=\"concl\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this article, we re-implemented the approach proposed by <a id=\"ref-33\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>, an investigation of the accurately tested feature sizes and proposed a new classifier. This classification approach, based on deep learning for detecting epileptic seizures using EGG, had not been explored previously. We adopted a self-concealment that allows us to construct a smaller representation space. Among the variety of metrics, our method stands out according to the ROC curve. The proposed approach still needs further investigation into the details of the parameters tested by the authors. The method is easily portable to other tasks and codes are a byproduct of this work. As future work, we can employ data augmentation that would allow the method to better learn the parameters adopted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--bibtex \n",
    "\n",
    "@Article{WenZha,\n",
    "    author = {Wen, Tingxi and Zhang, Zhongnan},\n",
    "    year = {2018},\n",
    "    month = {05},\n",
    "    pages = {1-1},\n",
    "    title = {Deep Convolution Neural Network and Autoencoders-based Unsupervised Feature Learning of EEG Signals},\n",
    "    volume = {PP},\n",
    "    journal = {IEEE Access},\n",
    "    doi = {10.1109/ACCESS.2018.2833746}\n",
    "}\n",
    "\n",
    "@Article{Shoeb,\n",
    " author = {Shoeb, Ali and Guttag, John},\n",
    " title = {Application of Machine Learning to Epileptic Seizure Detection},\n",
    " booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},\n",
    " series = {ICML'10},\n",
    " year = {2010},\n",
    " isbn = {978-1-60558-907-7},\n",
    " location = {Haifa, Israel},\n",
    " pages = {975--982},\n",
    " numpages = {8},\n",
    " url = {http://dl.acm.org/citation.cfm?id=3104322.3104446},\n",
    " acmid = {3104446},\n",
    " publisher = {Omnipress},\n",
    " address = {USA},\n",
    "} \n",
    "\n",
    "@Article{tensorflow,\n",
    "  title={Tensorflow: A system for large-scale machine learning},\n",
    "  author={Abadi, Mart{\\'\\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},\n",
    "  booktitle={12th $\\{$USENIX$\\}$ Symposium on Operating Systems Design and Implementation ($\\{$OSDI$\\}$ 16)},\n",
    "  pages={265--283},\n",
    "  year={2016}\n",
    "}\n",
    "\n",
    "@Article{how,\n",
    "  title={How Complex is your classification problem? A survey on measuring classification complexity},\n",
    "  author={Lorena, Ana C and Garcia, Lu{\\'\\i}s PF and Lehmann, Jens and Souto, Marcilio CP and Ho, Tin K},\n",
    "  journal={arXiv preprint arXiv:1808.03591},\n",
    "  year={2018}\n",
    "}\n",
    "\n",
    "@Article{andrzejak,\n",
    "    author = {G. Andrzejak, Ralph and Lehnertz, Klaus and Mormann, Florian and Rieke, Christoph and David, Peter and Elger, Christian},\n",
    "    year = {2002},\n",
    "    month = {01},\n",
    "    pages = {061907},\n",
    "    title = {Indications of nonlinear deterministic and finite-dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state},\n",
    "    volume = {64},\n",
    "    journal = {Physical review. E, Statistical, nonlinear, and soft matter physics},\n",
    "    doi = {10.1103/PhysRevE.64.061907}\n",
    "}\n",
    "\n",
    "@Article{kamath2015analysis,\n",
    "  title={Analysis of EEG dynamics in epileptic patients and healthy subjects using Hilbert transform scatter plots},\n",
    "  author={Kamath, Chandrakar},\n",
    "  journal={Open Access Library Journal},\n",
    "  volume={2},\n",
    "  number={1},\n",
    "  pages={1},\n",
    "  year={2015},\n",
    "  publisher={Scientific Research Publishing}\n",
    "}\n",
    "\n",
    "\n",
    "@Article{chollet2018keras,\n",
    "  title={Keras: The python deep learning library},\n",
    "  author={Chollet, Fran{\\c{c}}ois and others},\n",
    "  journal={Astrophysics Source Code Library},\n",
    "  year={2018}\n",
    "}\n",
    "\n",
    "@Article{benavoli2017time,\n",
    "  title={Time for a change: a tutorial for comparing multiple classifiers through Bayesian analysis},\n",
    "  author={Benavoli, Alessio and Corani, Giorgio and Dem{\\v{s}}ar, Janez and Zaffalon, Marco},\n",
    "  journal={The Journal of Machine Learning Research},\n",
    "  volume={18},\n",
    "  number={1},\n",
    "  pages={2653--2688},\n",
    "  year={2017},\n",
    "  publisher={JMLR. org}\n",
    "}\n",
    "\n",
    "@Article{Fuente:2019,\n",
    "  author = {la Fuente, Alfredo De and Aduviri, Robert},\n",
    "  title = {{[Re] Variational Sparse Coding}},\n",
    "  journal = {ReScience C},\n",
    "  year = {2019},\n",
    "  month = may,\n",
    "  volume = {5},\n",
    "  number = {2},\n",
    "  pages = {{\\#2}},\n",
    "  doi = {10.5281/zenodo.3161734},\n",
    "  url = {https://zenodo.org/record/3161734/files/Article.pdf},\n",
    "  code_url = {https://github.com/Alfo5123/Variational-Sparse-Coding},\n",
    "  code_doi = {10.5281/zenodo.2657330},\n",
    "  data_url = {},\n",
    "  data_doi = {},\n",
    "  review_url = {https://github.com/reproducibility-challenge/iclr_2019/pull/146},\n",
    "  type = {Replication},\n",
    "  language = {Python},\n",
    "  domain = {Machine Learning},\n",
    "  keywords = {generative models, variational autoencoders, sparse coding}\n",
    "}\n",
    "\n",
    "\n",
    "@Article{saab2005system,\n",
    "  title={A system to detect the onset of epileptic seizures in scalp EEG},\n",
    "  author={Saab, ME and Gotman, Jean},\n",
    "  journal={Clinical Neurophysiology},\n",
    "  volume={116},\n",
    "  number={2},\n",
    "  pages={427--442},\n",
    "  year={2005},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "\n",
    "\n",
    "@Article{kuhlmann2009seizure,\n",
    "  title={Seizure detection using seizure probability estimation: Comparison of features used to detect seizures},\n",
    "  author={Kuhlmann, Levin and Burkitt, Anthony N and Cook, Mark J and Fuller, Karen and Grayden, David B and Seiderer, Linda and Mareels, Iven MY},\n",
    "  journal={Annals of biomedical engineering},\n",
    "  volume={37},\n",
    "  number={10},\n",
    "  pages={2129--2145},\n",
    "  year={2009},\n",
    "  publisher={Springer}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "@Article{shoeb2004patient,\n",
    "  title={Patient-specific seizure onset detection},\n",
    "  author={Shoeb, Ali and Edwards, Herman and Connolly, Jack and Bourgeois, Blaise and Treves, S Ted and Guttag, John},\n",
    "  journal={Epilepsy \\& Behavior},\n",
    "  volume={5},\n",
    "  number={4},\n",
    "  pages={483--498},\n",
    "  year={2004},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "@Article{shoeb2011machine,\n",
    "  title={A machine-learning algorithm for detecting seizure termination in scalp EEG},\n",
    "  author={Shoeb, Ali and Kharbouch, Alaa and Soegaard, Jacqueline and Schachter, Steven and Guttag, John},\n",
    "  journal={Epilepsy \\& Behavior},\n",
    "  volume={22},\n",
    "  pages={S36--S43},\n",
    "  year={2011},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "\n",
    "\n",
    "@Article{ullah2018automated,\n",
    "  title={An automated system for epilepsy detection using EEG brain signals based on deep learning approach},\n",
    "  author={Ullah, Ihsan and Hussain, Muhammad and Aboalsamh, Hatim and others},\n",
    "  journal={Expert Systems with Applications},\n",
    "  volume={107},\n",
    "  pages={61--71},\n",
    "  year={2018},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "\n",
    "@Article{chua2011application,\n",
    "  title={Application of higher order spectra to identify epileptic EEG},\n",
    "  author={Chua, Kuang Chua and Chandran, Vinod and Acharya, U Rajendra and Lim, Choo Min},\n",
    "  journal={Journal of medical systems},\n",
    "  volume={35},\n",
    "  number={6},\n",
    "  pages={1563--1571},\n",
    "  year={2011},\n",
    "  publisher={Springer}\n",
    "}\n",
    "\n",
    "@Article{nicolaou2012detection,\n",
    "  title={Detection of epileptic electroencephalogram based on permutation entropy and support vector machines},\n",
    "  author={Nicolaou, Nicoletta and Georgiou, Julius},\n",
    "  journal={Expert Systems with Applications},\n",
    "  volume={39},\n",
    "  number={1},\n",
    "  pages={202--209},\n",
    "  year={2012},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "\n",
    "\n",
    "@Article{xun2016detecting,\n",
    "  title={Detecting epileptic seizures with electroencephalogram via a context-learning model},\n",
    "  author={Xun, Guangxu and Jia, Xiaowei and Zhang, Aidong},\n",
    "  journal={BMC medical informatics and decision making},\n",
    "  volume={16},\n",
    "  number={2},\n",
    "  pages={70},\n",
    "  year={2016},\n",
    "  publisher={BioMed Central}\n",
    "}\n",
    "\n",
    "@Article{acharya2018deep,\n",
    "  title={Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals},\n",
    "  author={Acharya, U Rajendra and Oh, Shu Lih and Hagiwara, Yuki and Tan, Jen Hong and Adeli, Hojjat},\n",
    "  journal={Computers in biology and medicine},\n",
    "  volume={100},\n",
    "  pages={270--278},\n",
    "  year={2018},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "\n",
    "\n",
    "@Article{emami2019autoencoding,\n",
    "  title={Autoencoding of long-term scalp electroencephalogram to detect epileptic seizure for diagnosis support system},\n",
    "  author={Emami, Ali and Kunii, Naoto and Matsuo, Takeshi and Shinozaki, Takashi and Kawai, Kensuke and Takahashi, Hirokazu},\n",
    "  journal={Computers in biology and medicine},\n",
    "  year={2019},\n",
    "  publisher={Elsevier}\n",
    "}\n",
    "\n",
    "@Article{hussein2018epileptic,\n",
    "  title={Epileptic seizure detection: A deep learning approach},\n",
    "  author={Hussein, Ramy and Palangi, Hamid and Ward, Rabab and Wang, Z Jane},\n",
    "  journal={arXiv preprint arXiv:1803.09848},\n",
    "  year={2018}\n",
    "}\n",
    "\n",
    "@Article{roy2019deep,\n",
    "  title={Deep learning-based electroencephalography analysis: a systematic review},\n",
    "  author={Roy, Yannick and Banville, Hubert and Albuquerque, Isabela and Gramfort, Alexandre and Falk, Tiago H and Faubert, Jocelyn},\n",
    "  journal={Journal of neural engineering},\n",
    "  year={2019},\n",
    "  publisher={IOP Publishing}\n",
    "}\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<a id=\"cite-WenZha\"/><sup><a href=#ref-1>[^]</a><a href=#ref-2>[^]</a><a href=#ref-13>[^]</a><a href=#ref-16>[^]</a><a href=#ref-20>[^]</a><a href=#ref-23>[^]</a><a href=#ref-24>[^]</a><a href=#ref-25>[^]</a><a href=#ref-29>[^]</a><a href=#ref-30>[^]</a><a href=#ref-33>[^]</a></sup>Wen, Tingxi and Zhang, Zhongnan. 2018. _Deep Convolution Neural Network and Autoencoders-based Unsupervised Feature Learning of EEG Signals_.\n",
    "\n",
    "<a id=\"cite-saab2005system\"/><sup><a href=#ref-3>[^]</a></sup>Saab, ME and Gotman, Jean. 2005. _A system to detect the onset of epileptic seizures in scalp EEG_.\n",
    "\n",
    "<a id=\"cite-kuhlmann2009seizure\"/><sup><a href=#ref-4>[^]</a></sup>Kuhlmann, Levin and Burkitt, Anthony N and Cook, Mark J and Fuller, Karen and Grayden, David B and Seiderer, Linda and Mareels, Iven MY. 2009. _Seizure detection using seizure probability estimation: Comparison of features used to detect seizures_.\n",
    "\n",
    "<a id=\"cite-shoeb2004patient\"/><sup><a href=#ref-5>[^]</a></sup>Shoeb, Ali and Edwards, Herman and Connolly, Jack and Bourgeois, Blaise and Treves, S Ted and Guttag, John. 2004. _Patient-specific seizure onset detection_.\n",
    "\n",
    "<a id=\"cite-shoeb2011machine\"/><sup><a href=#ref-6>[^]</a></sup>Shoeb, Ali and Kharbouch, Alaa and Soegaard, Jacqueline and Schachter, Steven and Guttag, John. 2011. _A machine-learning algorithm for detecting seizure termination in scalp EEG_.\n",
    "\n",
    "<a id=\"cite-ullah2018automated\"/><sup><a href=#ref-7>[^]</a><a href=#ref-15>[^]</a></sup>Ullah, Ihsan and Hussain, Muhammad and Aboalsamh, Hatim and others. 2018. _An automated system for epilepsy detection using EEG brain signals based on deep learning approach_.\n",
    "\n",
    "<a id=\"cite-chua2011application\"/><sup><a href=#ref-8>[^]</a></sup>Chua, Kuang Chua and Chandran, Vinod and Acharya, U Rajendra and Lim, Choo Min. 2011. _Application of higher order spectra to identify epileptic EEG_.\n",
    "\n",
    "<a id=\"cite-nicolaou2012detection\"/><sup><a href=#ref-9>[^]</a></sup>Nicolaou, Nicoletta and Georgiou, Julius. 2012. _Detection of epileptic electroencephalogram based on permutation entropy and support vector machines_.\n",
    "\n",
    "<a id=\"cite-acharya2018deep\"/><sup><a href=#ref-10>[^]</a></sup>Acharya, U Rajendra and Oh, Shu Lih and Hagiwara, Yuki and Tan, Jen Hong and Adeli, Hojjat. 2018. _Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals_.\n",
    "\n",
    "<a id=\"cite-hussein2018epileptic\"/><sup><a href=#ref-11>[^]</a></sup>Hussein, Ramy and Palangi, Hamid and Ward, Rabab and Wang, Z Jane. 2018. _Epileptic seizure detection: A deep learning approach_.\n",
    "\n",
    "<a id=\"cite-xun2016detecting\"/><sup><a href=#ref-12>[^]</a></sup>Xun, Guangxu and Jia, Xiaowei and Zhang, Aidong. 2016. _Detecting epileptic seizures with electroencephalogram via a context-learning model_.\n",
    "\n",
    "<a id=\"cite-emami2019autoencoding\"/><sup><a href=#ref-14>[^]</a><a href=#ref-22>[^]</a></sup>Emami, Ali and Kunii, Naoto and Matsuo, Takeshi and Shinozaki, Takashi and Kawai, Kensuke and Takahashi, Hirokazu. 2019. _Autoencoding of long-term scalp electroencephalogram to detect epileptic seizure for diagnosis support system_.\n",
    "\n",
    "<a id=\"cite-chollet2018keras\"/><sup><a href=#ref-17>[^]</a></sup>Chollet, Françcois and others. 2018. _Keras: The python deep learning library_.\n",
    "\n",
    "<a id=\"cite-tensorflow\"/><sup><a href=#ref-18>[^]</a></sup>Abadi, Martín and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others. undefined. _Tensorflow: A system for large-scale machine learning_.\n",
    "\n",
    "<a id=\"cite-Fuente:2019\"/><sup><a href=#ref-19>[^]</a></sup>la Fuente, Alfredo De and Aduviri, Robert. 2019. _[Re] Variational Sparse Coding_. [URL](https://zenodo.org/record/3161734/files/Article.pdf)\n",
    "\n",
    "<a id=\"cite-Shoeb\"/><sup><a href=#ref-21>[^]</a></sup>Shoeb, Ali and Guttag, John. 2010. _Application of Machine Learning to Epileptic Seizure Detection_. [URL](http://dl.acm.org/citation.cfm?id=3104322.3104446)\n",
    "\n",
    "<a id=\"cite-Andrzejak\"/><sup><a href=#ref-26>[^]</a></sup>G. Andrzejak, Ralph and Lehnertz, Klaus and Mormann, Florian and Rieke, Christoph and David, Peter and Elger, Christian. 2002. _Indications of nonlinear deterministic and finite-dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state_.\n",
    "\n",
    "<a id=\"cite-kamath2015analysis\"/><sup><a href=#ref-27>[^]</a></sup>Kamath, Chandrakar. 2015. _Analysis of EEG dynamics in epileptic patients and healthy subjects using Hilbert transform scatter plots_.\n",
    "\n",
    "<a id=\"cite-roy2019deep\"/><sup><a href=#ref-28>[^]</a></sup>Roy, Yannick and Banville, Hubert and Albuquerque, Isabela and Gramfort, Alexandre and Falk, Tiago H and Faubert, Jocelyn. 2019. _Deep learning-based electroencephalography analysis: a systematic review_.\n",
    "\n",
    "<a id=\"cite-how\"/><sup><a href=#ref-31>[^]</a></sup>Lorena, Ana C and Garcia, Luis PF and Lehmann, Jens and Souto, Marcilio CP and Ho, Tin K. 2018. _How Complex is your classification problem? A survey on measuring classification complexity_.\n",
    "\n",
    "<a id=\"cite-benavoli2017time\"/><sup><a href=#ref-32>[^]</a></sup>Benavoli, Alessio and Corani, Giorgio and Demsar, Janez and Zaffalon, Marco. 2017. _Time for a change: a tutorial for comparing multiple classifiers through Bayesian analysis_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendixes\n",
    "\n",
    "\n",
    "Retirar ou melhorar fluidez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.529Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "from baycomp import two_on_multiple\n",
    "\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "\n",
    "\n",
    "Our results are different of the ones showed in <a id=\"ref-30\" href=\"#cite-WenZha\">Wen and Zhang 2018</a>. However, we do not have full information about the implementation used to obtain the article results. Based on the original article results, we have two points of attention: one classifier had a result $36\\%$ below the expected, and the other one had $22\\%$ above the expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.539Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = merge_acc.reset_index().copy()\n",
    "acc = acc.drop(7).drop(['Ensemble','m'],1)\n",
    "acc.columns = ['k-NN','SVM1','SVM2','DT','RF','MLP','ADB','GNB']\n",
    "\n",
    "acc_baseline = pd.read_csv(\"../data/baseline/l1_dataset_1.csv\").drop(['AVG','m'],1)\n",
    "\n",
    "diff = pd.melt(acc - acc_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure [1](fig:boxplot) shows the difference between our results and the original ones. The relation between the vector's size and the classifiers accuracy is showed in Figure [2](fig:features-m-classifier). In this Figure we have on the $X$ axis the number of dimensions and on the $Y$ axis the accuracy of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.549Z"
    }
   },
   "outputs": [],
   "source": [
    "diff.columns = [\"\", \"\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "sns.set_context(\"paper\", font_scale=0.9)\n",
    "\n",
    "diff.columns = [\"Classifier\",\n",
    "                \"Difference between\\n obtained and reported accuracy.\"]\n",
    "\n",
    "ax = sns.boxplot(data=diff, \n",
    "            y=\"Difference between\\n obtained and reported accuracy.\", \n",
    "            x=\"Classifier\", ax=ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Figure 1: Accuracy difference between original results and our results. <a name=\"fig:boxplot\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.559Z"
    }
   },
   "outputs": [],
   "source": [
    "graph = pd.melt(merge_acc.reset_index(), id_vars=['m'])\n",
    "graph.columns = ['Number of Feature - m','Classifier','Accuracy']\n",
    "\n",
    "sns.set(rc={\"font.style\": \"normal\",\n",
    "            \"axes.facecolor\": (0.9, 0.9, 0.9),\n",
    "            \"figure.facecolor\": 'white',\n",
    "\n",
    "            'axes.labelsize': 30,\n",
    "            'figure.figsize': (20.0, 10.0),\n",
    "            'xtick.labelsize': 25,\n",
    "            'ytick.labelsize': 20})\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "\n",
    "sns.set(style=\"darkgrid\"),\n",
    "\n",
    "g = sns.lmplot(x=\"Number of Feature - m\", y='Accuracy', \n",
    "               hue='Classifier', col=\"Classifier\",\n",
    "               data=graph, height=5, aspect=.5, \n",
    "               x_jitter=.1, sharex=True, line_kws={\"lw\": 2, 'ls': '--'})\n",
    "\n",
    "\n",
    "g = g.set_axis_labels(\"\", \"Accuracy\").set(xlim=(-30, 280), ylim=(0.5, 1),\n",
    "                                          xticks=[0, 32, \n",
    "                                                  64, 128, \n",
    "                                                  256, 512]).fig.subplots_adjust(wspace=.4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Figure 2.: Features Number of autoencoder by accuracy, using linear regression. <a name=\"fig:features-m-classifier\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multilayer Neural Network classifier presents higher angular coefficient than the others, this increase in data volume that leads to the increase of the metric is consistent with the method premise. It is noteworthy that the Support Vector Machine with Linear Kernel also has a high coefficient. The highest Linear coefficient with the lowest associated uncertainty is found in the method proposed by us, the Ensemble method presents an initial result close to the best method for $ m = 2 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.570Z"
    }
   },
   "outputs": [],
   "source": [
    "print (\"\\tPrecision Results of AE-CDNN-L1 for Dataset 1\")\n",
    "display(np.around(merge_pre,3))\n",
    "print (\"\\tSpecificity Results of AE-CDNN-L1 for Dataset 1\")\n",
    "display(np.around(merge_spe,3))\n",
    "print (\"\\tSensitivity Results of AE-CDNN-L1 for Dataset 1\")\n",
    "display(np.around(merge_sen,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Table 3: Metric results to verify method behavior. <a name=\"#table:Precision-Specificity-Sensitivity\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T02:50:17.900616Z",
     "start_time": "2020-03-03T02:49:51.720Z"
    }
   },
   "source": [
    "By Table [3](#table:Precision-Specificity-Sensitivity), we realize that the most precise and specific method was the Gaussian Naive Bayesian; however, when analyzing the behavior in the Sensitivity metric, we do not have a satisfactory result. This indicates that the method pinpoints true negatives rather than true positives. If treated from a medical field, this result is worrying. The cases that the method indicates are true positives; however, this method misses many cases.\n",
    "\n",
    "We also analyze that we cannot consider SVM-1 or MLP results with the lowest $m$. The result in specificity indicates that the method behaves unwanted, possibly indicating all values as true positives. This rule burdens the medical system because further detection of the seizure requires further investigation for a complete diagnosis of the disease.\n",
    "\n",
    "By our method, we note that the three metrics indicate that a progression in the number of features generates an improvement in seizure detection. Similar behavior is observed in K-NN, only for accuracy and sensitivity, in this case, a beneficial behavior for the application. No trend was observed in the other methods. Attention is drawn to the $0$ values presented in the MLP, SVM1 methods. The average of the methods does not exceed our Ensemble method in any scenario. With the $m$ variation tested, we have that K-NN, RF, ADB worsen in specificity. Our method does not excel in these analyzed metrics.\n",
    "\n",
    "We analyze the behavior of the F-measure in Table [4](#table:F-Measure). The relationship between sensitivity and precision is captured by this measure, as the MLP, SVM-1, GNB methods did not obtain good results, which contradicts the accuracy result (Table [2](#table:accuracy)). The measures generally show close results with each other. Therefore, the factor to analyze here may be the complexity of the methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.582Z"
    }
   },
   "outputs": [],
   "source": [
    "display(np.around(merge_f1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Table 4: Classification F-Measure Results of AE-CDNN-L1 for Dataset 1. <a name=\"#table:F-Measure\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to <a id=\"ref-31\" href=\"#cite-how\">Loreta et al. 2018</a>, we have that the complexity of the task and the algorithms are decisive factors in deciding which methods will be used. Thus, as training is already costly, the complexity of the classification algorithm must be minimized. K-NN and ADB have lower complexity than the others, and a result close to the champion method. The difference in the performance of the SVM2 method in F-measure with our Ensemble method is close, the difference in averages is only $0.0002$. Also, looking at the behavior of the classifiers by the Bayesian Test (<a id=\"ref-32\" href=\"#cite-benavoli2017time\">Benavoli et al. 2017</a>), we have that the SVM2 method is $96.7\\%$ better than Ensemble on acurracy. We consider a more conservative analysis with rope = $0$ and runs= $5$, shown in Figure [3](#fig:acc-bay)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.590Z"
    }
   },
   "outputs": [],
   "source": [
    "names = (\"SVM2\", \"Ensemble\")\n",
    "probs, fig = two_on_multiple(\n",
    "    merge_acc['SVM2'], merge_acc['Ensemble'], runs=5, plot=True, names=names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Figure 3: Probabilities using a Bayesian signed-ranks test on Accurary. <a name=\"#fig:acc-bay\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in Table [5](#table:auc-roc) the performance of the AUC-ROC metric that the MLP method has the highest performance average, with $89.50\\% $, followed by Ensemble with $86.83\\%$. The methods that stand out in this metric showed no deficiency in the Sensitivity and Specificity metrics, given the construction of the measure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-27T20:56:38.598Z"
    }
   },
   "outputs": [],
   "source": [
    "display(np.around(merge_auc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Table 4: Classification AUC-ROC Results of AE-CDNN-L1 for Dataset 1 <a name=\"#table:auc-roc\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "re-science",
   "language": "python",
   "name": "re-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "691.75px",
    "left": "76px",
    "top": "699.333px",
    "width": "190.683px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
